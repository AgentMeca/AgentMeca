database:
  type: "chromadb"
  path: "./vector_db"
  persist_directory: true
  collection_name: "mecademic_chunks"

embeddings:
  # BGE-M3 for all chunks (unified model for better consistency)
  document_model:
    name: "BAAI/bge-m3"
    batch_size: 32
    device: "cpu"  # cpu/cuda
  
  # Use same model for code to avoid compatibility issues
  code_model:
    name: "BAAI/bge-m3"
    batch_size: 16
    device: "cpu"  # cpu/cuda

ingestion:
  source_directory: "./processed/semantic_chunks"
  validate_chunks: true
  skip_duplicates: true
  progress_reporting: true
  
  # Content type routing
  document_extensions: [".pdf", ".txt", ".md", ".html"]
  code_extensions: [".py", ".js", ".c", ".cpp", ".cs", ".java"]

search:
  default_limit: 10
  similarity_threshold: 0.7
  
storage:
  backup_directory: "./vector_db/backups"
  log_directory: "./vector_db/logs"